{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Objective    \n",
    "‚ùì Question  \n",
    "üìù Task  \n",
    "‚òëÔ∏è Instructions  \n",
    "üí° Informations  \n",
    "üíæ Submit your results  \n",
    "\n",
    "**variable name**  \n",
    "*field name*  \n",
    "`python object`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage automatique (Machine Learning) supervis√© et non supervis√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exam contains **9** sections.  \n",
    "\n",
    "For each one a time indication is given for information but you may choose your own pace.\n",
    "\n",
    "To pass the exam you need to validate at least **5** sections.  \n",
    "\n",
    "Some sections can be validated independently even if the exam use the same data for all of them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Your objective is to create a model that predicts the popularity of a song based on its characteristics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, you are given a dataset containing a list of songs with the following characteristics:\n",
    "\n",
    "**acousticness**: whether the track is acoustic  \n",
    "\n",
    "**danceability**: describes how suitable a track is for dancing  \n",
    "\n",
    "**duration_ms**: duration of the track in milliseconds  \n",
    "\n",
    "**energy**: represents a perceptual measure of intensity and activity  \n",
    "\n",
    "**explicit**: whether the track has explicit lyrics  \n",
    "\n",
    "**id**: id for the track  \n",
    "\n",
    "**instrumentalness**: predicts whether a track contains no vocals  \n",
    "\n",
    "**key**: the key the track is in  \n",
    "\n",
    "**liveness**: detects the presence of an audience in the recording  \n",
    "\n",
    "**loudness**: the overall loudness of a track in decibels  \n",
    "\n",
    "**mode**: modality of a track  \n",
    "\n",
    "**name**: name of the track  \n",
    "\n",
    "**popularity**: popularity of the track  \n",
    "\n",
    "**release_date**: release date  \n",
    "\n",
    "**speechiness**: detects the presence of spoken words in a track  \n",
    "\n",
    "**tempo**: overall estimated tempo of a track in beats per minute  \n",
    "\n",
    "**valence**: describes the musical positiveness conveyed by a track  \n",
    "\n",
    "**artist**: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òëÔ∏è Only fine-tune your model when explicitly asked to do so, in section *7 - Fine-tuning*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Cleaning (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C5 - Pr√©parer les donn√©es en vue de l'apprentissage afin que celles-ci soient nettoy√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Load and clean the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Load the data in **df**, a `DataFrame`  \n",
    "‚òëÔ∏è The data file is available at this url: https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Clean the data, make sure that no duplicates nor missing values remain in **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\"data_cleaning\", shape=df.shape)\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Supervised Learning (40 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C9 - Entra√Æner un mod√®le d'apprentissage supervis√© pour optimiser une fonction de pr√©diction √† partir d'exemples annot√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Identify your metrics, compute your baseline and evaluate a basic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Choose an appropriate scoring [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) from `sklearn` for this challenge, the chosen metric must:    \n",
    "\n",
    "‚òëÔ∏è strongly penalize largest errors relatively to smaller ones  \n",
    "‚òëÔ∏è measure errors in the same unit as the target `popularity`  \n",
    "‚òëÔ∏è the greater, the better (metric_good_model > metric_bad_model)  \n",
    "\n",
    "üìù Store in **scoring** its exact name as `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Define your features and target   \n",
    "\n",
    "‚òëÔ∏è Assign to **X_simple** a `DataFrame` containing only numerical features  \n",
    "‚òëÔ∏è Assign to **y** a `Series` containing only your target: *popularity*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Compute your baseline and store it in **baseline_score**, as a `float`  \n",
    "‚òëÔ∏è Do so by simulating a constant prediction equivalent to the mean value of your target  \n",
    "‚òëÔ∏è Use the same scoring function as the one stored in **scoring**  \n",
    "‚òëÔ∏è You may have to code the scoring function yourself to use it outside a `sklearn` workflow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Split your data, holding out 50% of observations, randomly sampled, as test set  \n",
    "‚òëÔ∏è  Assign the result of your holdout to **X_train_simple** **y_train**, **X_test_simple**, **y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Fit and evaluate the most basic linear model you can find in the [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module  \n",
    "‚òëÔ∏è Use the metric you stored in **scoring**    \n",
    "‚òëÔ∏è Store in **score_simple_holdout** your model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Cross-validate your basic model  \n",
    "‚òëÔ∏è Use 5 folds for your cross-validation  \n",
    "‚òëÔ∏è Store your mean score in **score_simple_cv_mean** as a `float`  \n",
    "‚òëÔ∏è Store the standard deviation of your scores in **score_simple_cv_std** as a `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òëÔ∏è From now on, you will stop using your train-test split    \n",
    "‚òëÔ∏è Instead we expect you to cross-validate (5 folds) your results with the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"supervised_learning\",\n",
    "    scoring=scoring,\n",
    "    baseline_score=baseline_score,\n",
    "    model=model_simple,\n",
    "    shape_train = X_train_simple.shape,\n",
    "    score_simple_holdout=score_simple_holdout,\n",
    "    score_simple_cv_mean=score_simple_cv_mean,\n",
    "    score_simple_cv_std=score_simple_cv_std,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Feature engineering (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C7 - G√©n√©rer des donn√©es d'entr√©e afin de satisfaire les contraintes inh√©rentes au mod√®les (Feature Engineering)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Create a new feature by extracting information from existing features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve performance using the feature *release_date*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a `DataFrame` **X_engineered** by adding a new column *year* to **X_simple**  \n",
    "‚òëÔ∏è *year* must contain the release year of the track as `integer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Check the impact of your new feature on the performance of your model  \n",
    "‚òëÔ∏è Retrain the same basic linear model you used in section 2  \n",
    "‚òëÔ∏è Use your **X_engineered** for the training  \n",
    "‚òëÔ∏è Save the mean score after cross-validation in **score_engineered** as a `float`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\"feature_engineering\",\n",
    "    cols = X_engineered.columns,\n",
    "    years = X_engineered.get(\"year\"),\n",
    "    score=score_engineered\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Unsupervised Learning (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C10 - Entra√Æner un mod√®le d'apprentissage non supervis√© pour d√©tecter des structures sous-jacentes √† partir de donn√©es non √©tiquet√©es*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Create a new feature by performing a clustering of your existing features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Use a `KMeans` to assign each track to a cluster  \n",
    "‚òëÔ∏è Your target number of clusters is 5  \n",
    "‚òëÔ∏è Fit your `KMeans` on **X_simple**  \n",
    "‚òëÔ∏è Store your fitted `KMeans` in **kmeans**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Add your clusters as features to your **X_engineered**  \n",
    "‚òëÔ∏è Use your **kmeans** to get cluster predictions on **X_simple**  \n",
    "‚òëÔ∏è Store the resulting predictions in a new column of **X_engineered** called *clusters*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Check the impact of your new *clusters* feature on the performance of your model  \n",
    "‚òëÔ∏è Retrain the same basic linear model you used in section 2 and 3  \n",
    "‚òëÔ∏è Use your **X_engineered**, with both *year* and *clusters* for the training  \n",
    "‚òëÔ∏è Save the mean score after cross-validation in **score_clusters** as a `float`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\"unsupervised_learning\",\n",
    "    cols=X_engineered.columns.tolist(),\n",
    "    clusters= kmeans.n_clusters,\n",
    "    labels=X_engineered['clusters'].value_counts(normalize=True).values,\n",
    "    score=score_clusters\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Preprocressing (1 h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C6 - Transformer les donn√©es d'entr√©e afin de satisfaire les contraintes inh√©rentes au mod√®le (Preprocessing)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Construct a preprocessing pipeline for your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# This will help you visualize your pipelines\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâ Do not hesitate to reload a clean new dataset if you need a fresh start.\n",
    "# X = \n",
    "# y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Look at your features with an `object` type in your **df**  \n",
    "‚òëÔ∏è Check their number of unique values  \n",
    "\n",
    "‚ùì Do you think it would be reasonable or efficient to one-hot encode any of them?  \n",
    "‚òëÔ∏è Store you answer as a string (Yes or No) in **answer_ohe** below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_ohe = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a custom transformer to extract the *year* from *release_date*  \n",
    "‚òëÔ∏è Use a [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html)  \n",
    "‚òëÔ∏è Store your custom transformer in **transformer_year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a pipeline **pipeline_year** with two steps:\n",
    "- your **transformer_year**  \n",
    "- a scaler that ensures values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù We provide you with a custom transformer to extract a cluster id for each observation  \n",
    "‚òëÔ∏è The [`transform`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.transform) method of a `KMeans` return an array of shape (n_samples, n_clusters) with the distance to cluster for each pair obs-cluster  \n",
    "‚òëÔ∏è We then simply use an `np.argmin` on the rows to get the index of the center the observation is closest to  \n",
    "‚òëÔ∏è This effectively yields clusters for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a pipeline **pipeline_clusters** with three steps:\n",
    "- a `KMeans` with a target number of clusters equals to 5  \n",
    "- your custom transformer **transformer_clusters**  \n",
    "- an encoder that creates a new binary column for each cluster - 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù We provide you with a custom Transformer Class below  \n",
    "‚òëÔ∏è Take some time to understand it  \n",
    "‚òëÔ∏è It computes the average popularity of songs, per artist, on the train set only  \n",
    "‚òëÔ∏è If the artist is unknown in the test set, the average popularity will be equal to the mean popularity on the train set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Compute, as a new feature the artist's popularity\n",
    "    Do so by computing the mean popularity of all songs from the artist\n",
    "    Notice that the popularity is computed on the train only to avoid leakage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "        self.artist_popularity = y.groupby(X.artist).agg(\"mean\")\n",
    "        self.artist_popularity.name = \"artist_popularity\"\n",
    "\n",
    "        # process mean popularity\n",
    "        self.mean_popularity = y.mean()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "\n",
    "        # inject artist popularity\n",
    "        X_copy = X.merge(self.artist_popularity, how=\"left\", left_on=\"artist\", right_index=True)\n",
    "\n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "        X_copy.replace(np.nan, self.mean_popularity, inplace=True)\n",
    "\n",
    "        return X_copy[[\"artist_popularity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a **pipeline_artist** with two steps:  \n",
    "- the custom `ArtistPopularityTransformer`  \n",
    "- a scaler that ensures values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a transformer that contains all your preprocessing steps using a [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html?highlight=column%20transformer#sklearn.compose.ColumnTransformer), which should:  \n",
    "‚òëÔ∏è Apply your **pipeline_clusters** to all numeric features  \n",
    "‚òëÔ∏è Scale all numeric features, so that their scaled values are within 0 and 1  \n",
    "‚òëÔ∏è Apply your **pipeline_year** to the *release_date* field  \n",
    "‚òëÔ∏è Apply your **pipeline_artist** to the *artist* field  \n",
    "‚òëÔ∏è Drop all other fields  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Use your pipeline to `transform` your **X** and store the result in **X_transformed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your preproc\n",
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"preprocessing\",\n",
    "    answer=answer_ohe,\n",
    "    shape=X_transformed.shape,\n",
    "    first_observation = X_transformed[0]\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Model Selection (40 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C8 - Ma√Ætriser les diff√©rents algorithmes d'apprentissage afin d'apporter une r√©ponse adapt√©e √† une probl√©matique d'une organisation (entreprise, laboratoire, etc.)*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Select the model that yields the best performance for your task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Try model from two different families: linear and ensemble  \n",
    "‚òëÔ∏è We expect you to cross-validate all scores with 5 folds in this section  \n",
    "\n",
    "**If you did not manage to construct the full preprocessing:**  \n",
    "‚òëÔ∏è Construct a light pipeline that use only features in **X_simple** and scale them to values between 0 and 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### 6.1 - Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Construct a `Pipeline` that combines your **preproc**  and a linear estimator from `sklearn`  \n",
    "‚òëÔ∏è Assign your pipeline to a variable named **pipe_linear**  \n",
    "‚òëÔ∏è We expect you to cross-validate all scores with 5 folds in this section  \n",
    "‚òëÔ∏è Store the mean of the scores in **score_linear**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Construct a `Pipeline` that combines your **preproc**  and an ensemble estimator from `sklearn`  \n",
    "‚òëÔ∏è Assign your pipeline to a variable named **pipe_ensemble**  \n",
    "‚òëÔ∏è We expect you to cross-validate all scores with 5 folds in this section  \n",
    "‚òëÔ∏è Store the mean of the scores in **score_ensemble**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\"model_selection\",\n",
    "    baseline=baseline_score,\n",
    "    estimator_linear=pipe_linear._final_estimator,\n",
    "    estimator_ensemble=pipe_ensemble._final_estimator,\n",
    "    score_linear=score_linear,\n",
    "    score_ensemble=score_ensemble)\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Fine-tuning (25 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C11 - Am√©liorer les capacit√©s pr√©dictives d'un syst√®mes en s√©lectionnant un mod√®le diff√©rent ou en modifiant ses hyperparam√®tres en vue de corriger des erreurs (hyperparameter tuning)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Fine-tune your best model to achieve the highest possible score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a cross-validated grid search and assign it to **search**  \n",
    "‚òëÔ∏è Choose the model that yielded the best result in section 6  \n",
    "‚òëÔ∏è Create a **grid**, a `dict`, that stores the hyperparameters you want to search  \n",
    "‚òëÔ∏è Limit yourself to 2 hyperparameters, with up to 3 possible values for each one  \n",
    "‚òëÔ∏è Use only one scoring method, the one you stored in **scoring** in section 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù fit your **search**  on the full **X** and **y**  \n",
    "‚òëÔ∏è Iterate until you notice an improvement on the best score  compared to the scores obtained in section 6  \n",
    "üí° You won't be judged by the computing power of your machine, your grid search should fit in under 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\"model_tuning\",\n",
    "    search_results=search.cv,\n",
    "    score=search.best_score_)\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Recommendations and Continuous Improvement (30 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C13 - Adopter une d√©marche d'am√©lioration continue en identifiant les axes de perfectionnement d'un produit √† l'aide d'une m√©thode adapt√©e de mani√®re √† am√©liorer la performance d'un produit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Transform your regression task into a classification task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product owner of your company tells you that he only needs to know whether a song is above or below popularity median  \n",
    "The exact popularity value is of little interest to her as it won't bring any value to the feature under development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Create a new target **y_cat**, a `Series`, using the formula below  \n",
    "\n",
    "‚òëÔ∏è $y\\_cat_i = 1 \\quad if\\quad y_i \\geq median(y),\\quad 0\\quad otherwise.$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù Cross validate a classification  \n",
    "\n",
    "‚òëÔ∏è Use your **preproc** with a basic linear model from `sklearn` suited for classification  \n",
    "‚òëÔ∏è Assign the resulting pipeline to **pipe_cat**  \n",
    "‚òëÔ∏è Cross validate the pipeline with 5 folds  \n",
    "‚òëÔ∏è Use the Accuracy metric and store the mean of scores in **score_cat**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"recommendations\",\n",
    "    target_cat = y_cat.value_counts(normalize=True).values,\n",
    "    model = pipe_cat._final_estimator,\n",
    "    score_cat = score_cat\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Deployment - API (40 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C12 - Mettre en production le mod√®le d'apprentissage supervis√© ou non supervis√© obtenu sous la forme d'une API*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù This challenge takes place in another repository  \n",
    "‚òëÔ∏è Follow the instructions provided on the certification platform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "239.844px",
    "left": "869.333px",
    "right": "20px",
    "top": "122px",
    "width": "348px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
